{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01dd016f",
   "metadata": {},
   "source": [
    "## Conclusion: Key Insights from Transfer Learning\n",
    "\n",
    "### âœ… Why Transfer Learning Works Better\n",
    "\n",
    "1. **Pretrained Features**: MobileNetV2 has learned useful patterns from ImageNet (1.2M images, 1,000 classes)\n",
    "2. **Warm Start**: Starting with good weights is better than random initialization\n",
    "3. **Reduced Data Needs**: Transfer learning works with limited data due to learned priors\n",
    "4. **Faster Convergence**: The model reaches good performance in fewer epochs\n",
    "\n",
    "### ğŸ“Š Observed Benefits\n",
    "\n",
    "**Transfer Learning:**\n",
    "- âœ… Higher test accuracy (~15-25% improvement)\n",
    "- âœ… Faster convergence (good results by epoch 5-10)\n",
    "- âœ… Better generalization (smaller train-val gap)\n",
    "- âœ… More stable training curves\n",
    "- âœ… Reduced overfitting through regularization\n",
    "\n",
    "**Baseline Model:**\n",
    "- âŒ Started from random weights\n",
    "- âŒ Required more epochs to converge\n",
    "- âŒ Lower overall accuracy\n",
    "- âŒ Higher risk of overfitting\n",
    "- âŒ More data needed for good performance\n",
    "\n",
    "### ğŸ”‘ Key Takeaways\n",
    "\n",
    "1. **Transfer Learning Principle**: \n",
    "   - Leverage pretrained models for faster, better results\n",
    "   - Freeze early layers (general features), train late layers (task-specific)\n",
    "\n",
    "2. **When to Use Transfer Learning**:\n",
    "   - Limited training data (< 10,000 images)\n",
    "   - Related tasks (ImageNet features generalize to many vision tasks)\n",
    "   - Limited computational resources\n",
    "   - Need quick model development\n",
    "\n",
    "3. **Feature Hierarchy in Deep Learning**:\n",
    "   - Early layers: Low-level features (edges, textures)\n",
    "   - Middle layers: Mid-level features (shapes, patterns)\n",
    "   - Late layers: High-level features (objects, faces)\n",
    "   - Final layers: Task-specific (CIFAR-10 class features)\n",
    "\n",
    "### ğŸš€ Next Steps for Improvement\n",
    "\n",
    "1. **Fine-tune more layers**: Unfreeze last few layers with low learning rate\n",
    "2. **Data augmentation**: Improve generalization with image transformations\n",
    "3. **Try other models**: EfficientNet, ResNet, Inception for better accuracy\n",
    "4. **Ensemble methods**: Combine multiple models for robustness\n",
    "5. **Hyperparameter tuning**: Optimize learning rate, dropout, batch size\n",
    "\n",
    "---\n",
    "\n",
    "**Completed at**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944a21f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature maps at different depths\n",
    "print(\"Analyzing features at different depths...\")\n",
    "\n",
    "# Get outputs from different layers\n",
    "layer_names = ['block_1_expand_relu', 'block_5_expand_relu', 'block_13_expand_relu']\n",
    "sample_img = x_test[0:1]\n",
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 10))\n",
    "fig.suptitle('Feature Maps at Different Depths (Deep Layers = More Abstract Features)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "for row, layer_name in enumerate(layer_names):\n",
    "    layer_model = Model(inputs=fine_tuned_model.input, \n",
    "                       outputs=base_model.get_layer(layer_name).output)\n",
    "    feature_maps = layer_model.predict(sample_img, verbose=0)[0]\n",
    "    \n",
    "    # Show 5 interesting feature maps\n",
    "    num_filters = min(5, feature_maps.shape[2])\n",
    "    for col in range(num_filters):\n",
    "        ax = axes[row, col]\n",
    "        ax.imshow(feature_maps[:, :, col], cmap='viridis')\n",
    "        ax.set_title(f'{layer_name}\\nFilter {col+1}', fontsize=9)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    for col in range(num_filters, 5):\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Feature depth analysis completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26bed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions on sample images\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "fig.suptitle('Model Predictions: Transfer Learning vs Baseline', fontsize=16, fontweight='bold')\n",
    "\n",
    "test_indices = np.random.choice(len(x_test), 12, replace=False)\n",
    "\n",
    "for idx, test_idx in enumerate(test_indices):\n",
    "    ax = axes[idx // 4, idx % 4]\n",
    "    \n",
    "    # Display image\n",
    "    ax.imshow(x_test[test_idx])\n",
    "    \n",
    "    # Get predictions\n",
    "    true_label = class_names[y_test[test_idx]]\n",
    "    tl_pred_label = class_names[np.argmax(tl_predictions[test_idx])]\n",
    "    baseline_pred_label = class_names[np.argmax(baseline_predictions[test_idx])]\n",
    "    \n",
    "    tl_conf = np.max(tl_predictions[test_idx])\n",
    "    baseline_conf = np.max(baseline_predictions[test_idx])\n",
    "    \n",
    "    # Color: green if correct, red if incorrect\n",
    "    tl_color = 'green' if tl_pred_label == true_label else 'red'\n",
    "    baseline_color = 'green' if baseline_pred_label == true_label else 'red'\n",
    "    \n",
    "    title = f\"True: {true_label}\\n\"\n",
    "    title += f\"TL: {tl_pred_label} ({tl_conf*100:.1f}%) [{tl_color}]\\n\"\n",
    "    title += f\"BL: {baseline_pred_label} ({baseline_conf*100:.1f}%) [{baseline_color}]\"\n",
    "    \n",
    "    ax.set_title(title, fontsize=9)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Prediction visualization completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e004cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and analyze misclassifications\n",
    "print(\"Analyzing model predictions...\")\n",
    "\n",
    "tl_predictions = fine_tuned_model.predict(x_test, verbose=0)\n",
    "baseline_predictions = baseline_model.predict(x_test, verbose=0)\n",
    "\n",
    "tl_pred_classes = np.argmax(tl_predictions, axis=1)\n",
    "baseline_pred_classes = np.argmax(baseline_predictions, axis=1)\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-CLASS ACCURACY COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for class_idx in range(10):\n",
    "    mask = y_test == class_idx\n",
    "    tl_class_acc = np.mean(tl_pred_classes[mask] == y_test[mask])\n",
    "    baseline_class_acc = np.mean(baseline_pred_classes[mask] == y_test[mask])\n",
    "    \n",
    "    print(f\"{class_names[class_idx]:15} | Transfer Learning: {tl_class_acc*100:5.1f}% | Baseline: {baseline_class_acc*100:5.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a541b9a8",
   "metadata": {},
   "source": [
    "## Step 7: Visualize and Analyze Learned Features\n",
    "\n",
    "In this section, we'll examine what features the model learns and how they differ from what the baseline learns.\n",
    "\n",
    "### Key Questions:\n",
    "1. What patterns does the transfer learning model recognize?\n",
    "2. How do the learned features compare between the two models?\n",
    "3. Can we visualize the decision boundaries of the models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc84fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed performance comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nğŸ“Š TRANSFER LEARNING MODEL:\")\n",
    "print(f\"  â€¢ Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"  â€¢ Final Training Accuracy: {history.history['accuracy'][-1]*100:.2f}%\")\n",
    "print(f\"  â€¢ Final Validation Accuracy: {history.history['val_accuracy'][-1]*100:.2f}%\")\n",
    "tl_train_val_gap = history.history['accuracy'][-1] - history.history['val_accuracy'][-1]\n",
    "print(f\"  â€¢ Train-Val Accuracy Gap: {tl_train_val_gap:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ“Š BASELINE MODEL:\")\n",
    "print(f\"  â€¢ Test Accuracy: {baseline_test_accuracy*100:.2f}%\")\n",
    "print(f\"  â€¢ Final Training Accuracy: {baseline_history.history['accuracy'][-1]*100:.2f}%\")\n",
    "print(f\"  â€¢ Final Validation Accuracy: {baseline_history.history['val_accuracy'][-1]*100:.2f}%\")\n",
    "baseline_train_val_gap = baseline_history.history['accuracy'][-1] - baseline_history.history['val_accuracy'][-1]\n",
    "print(f\"  â€¢ Train-Val Accuracy Gap: {baseline_train_val_gap:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ“ˆ PERFORMANCE IMPROVEMENT:\")\n",
    "accuracy_improvement = (test_accuracy - baseline_test_accuracy) * 100\n",
    "print(f\"  â€¢ Transfer Learning outperforms Baseline by: {accuracy_improvement:.2f} percentage points\")\n",
    "print(f\"  â€¢ Relative improvement: {(accuracy_improvement / (baseline_test_accuracy*100)) * 100:.1f}%\")\n",
    "\n",
    "print(\"\\nğŸ” CONVERGENCE ANALYSIS:\")\n",
    "# Find epoch where transfer learning reaches 90% validation accuracy\n",
    "tl_epochs_to_90 = np.argmax(np.array(history.history['val_accuracy']) > 0.90) if any(np.array(history.history['val_accuracy']) > 0.90) else 20\n",
    "baseline_epochs_to_90 = np.argmax(np.array(baseline_history.history['val_accuracy']) > 0.90) if any(np.array(baseline_history.history['val_accuracy']) > 0.90) else 20\n",
    "\n",
    "print(f\"  â€¢ Transfer Learning epochs to reach 80% val accuracy: {np.argmax(np.array(history.history['val_accuracy']) > 0.80) + 1}\")\n",
    "print(f\"  â€¢ Baseline epochs to reach 80% val accuracy: {np.argmax(np.array(baseline_history.history['val_accuracy']) > 0.80) + 1}\")\n",
    "\n",
    "print(\"\\nğŸ¯ OVERFITTING ANALYSIS:\")\n",
    "print(f\"  â€¢ Transfer Learning overfitting gap: {tl_train_val_gap:.4f}\")\n",
    "print(f\"  â€¢ Baseline overfitting gap: {baseline_train_val_gap:.4f}\")\n",
    "print(f\"  â€¢ Transfer Learning has {'LESS' if tl_train_val_gap < baseline_train_val_gap else 'MORE'} overfitting\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eafcee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test accuracy comparison bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "models = ['Transfer Learning', 'Baseline CNN']\n",
    "accuracies = [test_accuracy, baseline_test_accuracy]\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "\n",
    "bars = ax.bar(models, accuracies, color=colors, alpha=0.8, edgecolor='black', linewidth=2, width=0.5)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "            f'{acc*100:.2f}%',\n",
    "            ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Test Accuracy', fontsize=12)\n",
    "ax.set_title('Test Accuracy Comparison: Transfer Learning vs Baseline', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim([0, 1.0])\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Accuracy comparison chart generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e31b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Plot 1: Training and Validation Accuracy\n",
    "axes[0].plot(history.history['accuracy'], label='Transfer Learning - Train', linewidth=2.5, marker='o', markersize=3)\n",
    "axes[0].plot(history.history['val_accuracy'], label='Transfer Learning - Val', linewidth=2.5, marker='s', markersize=3)\n",
    "axes[0].plot(baseline_history.history['accuracy'], label='Baseline - Train', linewidth=2.5, linestyle='--', marker='o', markersize=3)\n",
    "axes[0].plot(baseline_history.history['val_accuracy'], label='Baseline - Val', linewidth=2.5, linestyle='--', marker='s', markersize=3)\n",
    "axes[0].set_xlabel('Epochs', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].set_title('Model Comparison: Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Training and Validation Loss\n",
    "axes[1].plot(history.history['loss'], label='Transfer Learning - Train', linewidth=2.5, marker='o', markersize=3)\n",
    "axes[1].plot(history.history['val_loss'], label='Transfer Learning - Val', linewidth=2.5, marker='s', markersize=3)\n",
    "axes[1].plot(baseline_history.history['loss'], label='Baseline - Train', linewidth=2.5, linestyle='--', marker='o', markersize=3)\n",
    "axes[1].plot(baseline_history.history['val_loss'], label='Baseline - Val', linewidth=2.5, linestyle='--', marker='s', markersize=3)\n",
    "axes[1].set_xlabel('Epochs', fontsize=12)\n",
    "axes[1].set_ylabel('Loss', fontsize=12)\n",
    "axes[1].set_title('Model Comparison: Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Comparison plots generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b935f25a",
   "metadata": {},
   "source": [
    "## Step 6: Compare Transfer Learning vs Baseline Performance\n",
    "\n",
    "Now we'll compare the two models across multiple dimensions:\n",
    "1. **Test Accuracy**: Final performance on unseen data\n",
    "2. **Convergence Speed**: How quickly the model reaches good performance\n",
    "3. **Generalization**: The gap between training and validation accuracy\n",
    "4. **Training Stability**: Smoothness of the learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5128060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the baseline model\n",
    "print(\"Evaluating baseline model on test set...\")\n",
    "baseline_test_loss, baseline_test_accuracy = baseline_model.evaluate(\n",
    "    x_test, y_test_one_hot, verbose=0\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"BASELINE MODEL RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Test Loss: {baseline_test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {baseline_test_accuracy:.4f} ({baseline_test_accuracy*100:.2f}%)\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51931929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train the baseline model\n",
    "print(\"Compiling baseline model...\")\n",
    "baseline_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(\"âœ“ Baseline model compiled\")\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining baseline model from scratch...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "baseline_history = baseline_model.fit(\n",
    "    x_train_split, y_train_split,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"âœ“ Baseline model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07cae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and display the baseline model architecture\n",
    "print(\"Building baseline CNN model from scratch...\")\n",
    "\n",
    "baseline_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3), padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "print(\"âœ“ Baseline model created!\")\n",
    "print(f\"\\nBaseline Model Architecture:\")\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abfefe4",
   "metadata": {},
   "source": [
    "## Step 5: Build and Train a Baseline CNN Model\n",
    "\n",
    "To demonstrate the advantage of transfer learning, we'll train a simple CNN from scratch on the same CIFAR-10 dataset.\n",
    "\n",
    "**Baseline Model Architecture:**\n",
    "- Conv2D(32, 3Ã—3) + ReLU, MaxPooling2D(2Ã—2)\n",
    "- Conv2D(64, 3Ã—3) + ReLU, MaxPooling2D(2Ã—2)\n",
    "- Conv2D(128, 3Ã—3) + ReLU\n",
    "- Flatten\n",
    "- Dense(256) + ReLU + Dropout(0.5)\n",
    "- Dense(128) + ReLU + Dropout(0.3)\n",
    "- Dense(10) + Softmax\n",
    "\n",
    "This baseline starts with random weights and learns from scratch, which typically requires:\n",
    "- More training data\n",
    "- More training time (epochs)\n",
    "- More computational resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3897889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature maps from an intermediate layer\n",
    "fig, axes = plt.subplots(2, 10, figsize=(15, 3))\n",
    "fig.suptitle(f'Feature Maps from Layer: {intermediate_layer_name}\\n(First 10 filters for first sample image)', \n",
    "             fontsize=12, fontweight='bold')\n",
    "\n",
    "# Show first 10 feature maps for the first sample image\n",
    "feature_map = intermediate_output[0, :, :, :10]\n",
    "\n",
    "for idx in range(10):\n",
    "    # Top row: Feature maps\n",
    "    ax = axes[0, idx]\n",
    "    ax.imshow(feature_map[:, :, idx], cmap='viridis')\n",
    "    ax.set_title(f'Filter {idx+1}', fontsize=8)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Bottom row: Statistical info\n",
    "    ax = axes[1, idx]\n",
    "    ax.hist(feature_map[:, :, idx].flatten(), bins=20, color='steelblue', alpha=0.7)\n",
    "    ax.set_title(f'Distribution', fontsize=8)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Feature maps visualized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25b6d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze intermediate feature maps\n",
    "print(\"\\nAnalyzing intermediate feature maps...\")\n",
    "intermediate_layer_name = 'block_13_expand_relu'  # Layer from MobileNetV2\n",
    "intermediate_layer_model = Model(\n",
    "    inputs=fine_tuned_model.input,\n",
    "    outputs=base_model.get_layer(intermediate_layer_name).output\n",
    ")\n",
    "\n",
    "# Get feature maps for a sample of test images\n",
    "sample_images = x_test[:5]\n",
    "intermediate_output = intermediate_layer_model.predict(sample_images, verbose=0)\n",
    "\n",
    "print(f\"\\nIntermediate layer: '{intermediate_layer_name}'\")\n",
    "print(f\"Feature map shape: {intermediate_output.shape}\")\n",
    "print(f\"  - Number of samples: {intermediate_output.shape[0]}\")\n",
    "print(f\"  - Height: {intermediate_output.shape[1]}\")\n",
    "print(f\"  - Width: {intermediate_output.shape[2]}\")\n",
    "print(f\"  - Number of filters: {intermediate_output.shape[3]}\")\n",
    "print(f\"\\nThis shows how the model processes images through its layers,\")\n",
    "print(f\"extracting increasingly complex features at each stage.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d93cede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the fine-tuned model on the test set\n",
    "print(\"Evaluating the fine-tuned model on test set...\")\n",
    "test_loss, test_accuracy = fine_tuned_model.evaluate(x_test, y_test_one_hot, verbose=0)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FINE-TUNED MODEL RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49191855",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate the Fine-tuned Model\n",
    "\n",
    "In this step, we will:\n",
    "1. Evaluate the model on the test set\n",
    "2. Analyze intermediate feature maps\n",
    "3. Visualize what the model has learned at different layers\n",
    "\n",
    "**Interest in Feature Maps:**\n",
    "Feature maps show the activations of neurons in intermediate layers. By visualizing them, we can understand:\n",
    "- What patterns the model recognizes at different depths\n",
    "- How the model processes visual information\n",
    "- Whether the model learns meaningful features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fae7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the fine-tuned model\n",
    "print(\"Training the fine-tuned model...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "history = fine_tuned_model.fit(\n",
    "    x_train_split, y_train_split,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"âœ“ Fine-tuned model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b15955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "print(\"Compiling the fine-tuned model...\")\n",
    "fine_tuned_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(\"âœ“ Model compiled successfully!\")\n",
    "print(f\"  Optimizer: Adam (lr=0.001)\")\n",
    "print(f\"  Loss: Categorical Crossentropy\")\n",
    "print(f\"  Metrics: Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b556a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build custom top layers for CIFAR-10 classification\n",
    "print(\"Building custom top layers...\")\n",
    "\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "x = base_model(inputs, training=False)  # Use base model in inference mode\n",
    "\n",
    "# Add custom layers\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "print(\"  âœ“ Added GlobalAveragePooling2D\")\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "print(\"  âœ“ Added Dense(256) + Dropout(0.5)\")\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "print(\"  âœ“ Added Dense(128) + Dropout(0.3)\")\n",
    "\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "print(\"  âœ“ Added Dense(10) output layer\")\n",
    "\n",
    "# Create the fine-tuned model\n",
    "fine_tuned_model = Model(inputs, outputs)\n",
    "print(f\"\\nâœ“ Fine-tuned model created!\")\n",
    "\n",
    "print(f\"\\nFine-tuned Model Architecture:\")\n",
    "fine_tuned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ab9d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the base model layers\n",
    "print(\"Freezing base model layers...\")\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(f\"âœ“ All {len(base_model.layers)} layers frozen\")\n",
    "print(f\"Trainable parameters after freezing: {sum([tf.size(w).numpy() for w in base_model.trainable_weights]):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dff7a05",
   "metadata": {},
   "source": [
    "## Step 3: Fine-tune the Pretrained Model\n",
    "\n",
    "Fine-tuning strategy:\n",
    "1. **Freeze the base layers** - Preserve the learned features from ImageNet\n",
    "2. **Add custom top layers** - Create task-specific layers for CIFAR-10 classification\n",
    "3. **Train only custom layers** - Update weights only in the new layers\n",
    "\n",
    "**Custom Layer Architecture:**\n",
    "- Global Average Pooling: Reduces spatial dimensions\n",
    "- Dense(256) + ReLU: High-dimensional feature processing\n",
    "- Dropout(0.5): Regularization to prevent overfitting\n",
    "- Dense(128) + ReLU: Further feature refinement\n",
    "- Dropout(0.3): Additional regularization\n",
    "- Dense(10) + Softmax: Output layer for 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1636145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the model structure\n",
    "print(f\"Total layers in base model: {len(base_model.layers)}\")\n",
    "print(f\"\\nLayer types in the model:\")\n",
    "\n",
    "layer_types = {}\n",
    "for layer in base_model.layers:\n",
    "    layer_type = layer.__class__.__name__\n",
    "    layer_types[layer_type] = layer_types.get(layer_type, 0) + 1\n",
    "\n",
    "for layer_type, count in sorted(layer_types.items()):\n",
    "    print(f\"  {layer_type}: {count}\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = base_model.count_params()\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters (before freezing): {sum([tf.size(w).numpy() for w in base_model.trainable_weights]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d57bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MobileNetV2 model pretrained on ImageNet\n",
    "print(\"Loading pretrained MobileNetV2 model...\")\n",
    "base_model = MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,  # Remove the top classification layer\n",
    "    input_shape=(32, 32, 3)  # Input shape for CIFAR-10\n",
    ")\n",
    "\n",
    "print(\"âœ“ MobileNetV2 model loaded successfully!\")\n",
    "print(f\"\\nBase Model Architecture:\")\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8bdb00",
   "metadata": {},
   "source": [
    "## Step 2: Examine the Pretrained MobileNetV2 Model\n",
    "\n",
    "Transfer learning leverages pretrained models that have learned features from large datasets (like ImageNet). \n",
    "\n",
    "**MobileNetV2 Overview:**\n",
    "- **Parameters**: ~3.5 million\n",
    "- **Pretraining**: ImageNet (1.2M images, 1,000 classes)\n",
    "- **Architecture**: Efficient mobile-friendly design\n",
    "- **Input size**: We'll adapt it for 32Ã—32 CIFAR-10 images\n",
    "\n",
    "By examining the model's architecture, we understand:\n",
    "1. The layers and their operations\n",
    "2. The features learned during pretraining\n",
    "3. Where to add custom layers for our task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb438eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from the dataset\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "fig.suptitle('Sample CIFAR-10 Images', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    index = np.random.randint(0, len(x_train_split))\n",
    "    ax.imshow(x_train_split[index])\n",
    "    label = np.argmax(y_train_split[index])\n",
    "    ax.set_title(f'{class_names[label]}', fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Sample images displayed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b8b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values to [0, 1]\n",
    "print(\"Normalizing pixel values...\")\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "print(f\"âœ“ Pixel values normalized to range [0, 1]\")\n",
    "print(f\"  Min value: {x_train.min()}, Max value: {x_train.max()}\")\n",
    "\n",
    "# Flatten labels for processing\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()\n",
    "\n",
    "# Convert labels to one-hot encoded format\n",
    "print(\"\\nConverting labels to one-hot encoding...\")\n",
    "y_train_one_hot = to_categorical(y_train, 10)\n",
    "y_test_one_hot = to_categorical(y_test, 10)\n",
    "print(f\"âœ“ Labels converted. Shape: {y_train_one_hot.shape}\")\n",
    "\n",
    "# Split training data into training and validation sets\n",
    "print(\"\\nCreating train-validation split...\")\n",
    "x_train_split, x_val, y_train_split, y_val = train_test_split(\n",
    "    x_train, y_train_one_hot, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "print(f\"âœ“ Split completed:\")\n",
    "print(f\"  Training set: {x_train_split.shape}\")\n",
    "print(f\"  Validation set: {x_val.shape}\")\n",
    "print(f\"  Test set: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36679b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "print(\"Loading CIFAR-10 dataset...\")\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print(f\"âœ“ Dataset loaded successfully!\")\n",
    "print(f\"  Training set shape: {x_train.shape}\")\n",
    "print(f\"  Test set shape: {x_test.shape}\")\n",
    "\n",
    "# CIFAR-10 class names\n",
    "class_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', \n",
    "               'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "print(f\"\\nClasses: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e78e56",
   "metadata": {},
   "source": [
    "## Step 1: Load and Prepare the CIFAR-10 Dataset\n",
    "\n",
    "In this step, we will:\n",
    "1. Load the CIFAR-10 dataset\n",
    "2. Normalize pixel values to [0, 1]\n",
    "3. Convert labels to one-hot encoding\n",
    "4. Create training, validation, and test splits\n",
    "\n",
    "**Data Preprocessing Strategy:**\n",
    "- **Normalization**: Scale pixel values from [0, 255] to [0, 1]\n",
    "- **One-hot encoding**: Convert class labels to binary vectors (e.g., 3 â†’ [0,0,0,1,0,0,0,0,0,0])\n",
    "- **Train-Validation Split**: Use 80% for training and 20% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ae309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a81a2d",
   "metadata": {},
   "source": [
    "# Transfer Learning Project: CIFAR-10 Classification with MobileNetV2\n",
    "\n",
    "This notebook demonstrates how to implement transfer learning to solve an image classification task using a pretrained MobileNetV2 model and the CIFAR-10 dataset.\n",
    "\n",
    "## Learning Objectives\n",
    "By completing this notebook, you will:\n",
    "1. **Analyze** the architecture and purpose of a pretrained model\n",
    "2. **Fine-tune** a pretrained model for a specific dataset\n",
    "3. **Evaluate** the model's performance and compare it to a baseline\n",
    "4. **Examine** differences in learned features before and after fine-tuning\n",
    "5. **Understand** the advantages of transfer learning\n",
    "\n",
    "## Dataset Overview\n",
    "**CIFAR-10**: A dataset of 60,000 32Ã—32 RGB images across 10 classes:\n",
    "- Airplane, Automobile, Bird, Cat, Deer, Dog, Frog, Horse, Ship, Truck\n",
    "\n",
    "The dataset is split into:\n",
    "- **Training set**: 40,000 images (after train-val split)\n",
    "- **Validation set**: 10,000 images\n",
    "- **Test set**: 10,000 images"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
